} else if (i == 3){
var_aic_sub <- var_aic[var_aic$Modnames == summary_mod_vars_sep[[h]], ]
var_aic_null <- var_aic[var_aic$Modnames == summary_mod_null_sep[[h]], ]
summary_models[,9][[h]] <- var_aic_sub$Delta_AICc - var_aic_null$Delta_AICc
} else if (i == 4){
var_aic_sub <- var_aic[var_aic$Modnames == summary_mod_vars_sep[[h]], ]
var_aic_null <- var_aic[var_aic$Modnames == summary_mod_null_sep[[h]], ]
summary_models[,10][[h]] <- var_aic_sub$Delta_AICc - var_aic_null$Delta_AICc
}
View(summary_models)
summary_mod_null_sep[[h]]
View(var_aic)
effects
summary_mod_null_all[[h]]
summary_models <- data.frame(
"prediction" = c("1.0", "1.1", "1.2a", "1.2b", "1.2c1, 1.3a1", "1.2c2", "1.3b1", "1.3a2", "1.3b2", "2.1", "2.2"),
"model_vars_all_years" =
c("resist.value ~ dbh_ln+year+(1|sp/tree)",
"resist.value ~ height_ln+year+(1|sp/tree)",
"resist.value ~ position+year+(1|sp/tree)",
"resist.value ~ position+height_ln+year+(1|sp/tree)",
"resist.value ~ elev_m+height_ln+year+(1|sp/tree)",
"resist.value ~ elev_m*height_ln+height_ln+year+(1|sp/tree)",
"resist.value ~ distance_ln+height_ln+year+(1|sp/tree)",
"resist.value ~ distance_ln*height_ln+height_ln+year+(1|sp/tree)",
"resist.value ~ tlp+height_ln+year+(1|sp/tree)",
"resist.value ~ rp+height_ln+year+(1|sp/tree)"),
"null_model_all_years" = NA,
"model_vars_sep_years" = NA,
"null_model_sep_years" = NA,
# "null_model_all_years" = c("resist.value ~ year+(1|sp/tree)", "resist.value ~ year+(1|sp/tree)", "resist.value ~ year+(1|sp/tree)", "resist.value ~ height_ln+year+(1|sp/tree)", "resist.value ~ height_ln+year+(1|sp/tree)", "resist.value ~ height_ln+year+(1|sp/tree)", "resist.value ~ height_ln+year+(1|sp/tree)", "resist.value ~ height_ln+year+(1|sp/tree)", "resist.value ~ height_ln+year+(1|sp/tree)", "resist.value ~ height_ln+year+(1|sp/tree)", "resist.value ~ height_ln+year+(1|sp/tree)"),
# "null_model_sep_years" = c("resist.value ~ (1|sp)", "resist.value ~ (1|sp)", "resist.value ~ (1|sp)", "resist.value ~ height_ln+(1|sp)", "resist.value ~ height_ln+(1|sp)", "resist.value ~ height_ln+(1|sp)", "resist.value ~ height_ln+(1|sp)", "resist.value ~ height_ln+(1|sp)", "resist.value ~ height_ln+(1|sp)", "resist.value ~ height_ln+(1|sp)", "resist.value ~ height_ln+(1|sp)"),
"response_direction" = c(NA, "-", "canopy<subcanopy", "canopy<subcanopy", "+", "+", "-", "+", "-", "-", "ring>diffuse"),
"dAIC_all_years" = NA,
"dAIC_1964-1966" = NA,
"dAIC_1977" = NA,
"dAIC_1999" = NA)
library(dplyr)
# change factor columns to character
summary_models %>% mutate_if(is.factor, as.character) -> summary_models
summary_models[c(1:3), 3] <- "resist.value ~ year+(1|sp/tree)"
summary_models[c(4:11), 3] <- "resist.value ~ height_ln+year+(1|sp/tree)"
summary_models$model_vars_sep_years <- gsub("year\\+|/tree", "", summary_models$model_vars_all_years)
summary_models$null_model_sep_years <- gsub("year\\+|/tree", "", summary_models$null_model_all_years)
summary_mod_vars_all <- summary_models$model_vars_all_years
summary_mod_vars_sep <- summary_models$model_vars_sep_years
summary_mod_null_all <- summary_models$null_model_all_years
summary_mod_null_sep <- summary_models$null_model_sep_years
all_effects <- colnames(trees_all)
for (i in seq_along(model_df)){
for (h in seq(along=summary_mod_vars_all)){
if (i==1){
#define response and effects
response <- gsub(" ~.*", "", summary_mod_vars_all[[h]])
effects <- unlist(strsplit(summary_mod_vars_all[[h]], "\\+|~ "))[-1]
# all fixed effects <- c("position", "tlp", "rp", "elev_m", "dbh_ln", "height_ln", "year")
#create all combinations of random / fixed effects
effects_comb <-
unlist( sapply( seq_len(length(effects)),
function(i) {
apply( combn(effects,i), 2, function(x) paste(x, collapse = "+"))
}))
# pair response with effect and sub out combinations that don't include random effects
#in general, if two variables are >70% correlated, you can toss one of them without significantly affecting the results
var_comb <- expand.grid(response, effects_comb)
var_comb <- var_comb[grepl("1", var_comb$Var2), ] #only keep in fixed/random combos
var_comb <- var_comb[grepl("year", var_comb$Var2), ] #keep year in for drought sake
} else {
#define response and effects
response <- gsub(" ~.*", "", summary_mod_vars_sep[[h]])
effects <- unlist(strsplit(summary_mod_vars_sep[[h]], "\\+|~ "))[-1]
# all fixed effects <- c("position", "tlp", "rp", "elev_m", "dbh_ln", "height_ln")
#create all combinations of random / fixed effects
effects_comb <-
unlist( sapply( seq_len(length(effects)),
function(i) {
apply( combn(effects,i), 2, function(x) paste(x, collapse = "+"))
}))
# pair response with effect and sub out combinations that don't include random effects
#in general, if two variables are >70% correlated, you can toss one of them without significantly affecting the results
var_comb <- expand.grid(response, effects_comb)
var_comb <- var_comb[grepl("1", var_comb$Var2), ] #only keep in fixed+random combos
}
# formulas for all combinations. $Var1 is the response, and $Var2 is the effect
# for good stats, you should have no more total parameters than 1/10th the number of observations in your dataset
formula_vec <- sprintf("%s ~ %s", var_comb$Var1, var_comb$Var2)
# create list of model outputs
lmm_all <- lapply(formula_vec, function(x){
fit1 <- lmer(x, data = model_df[[i]], REML=FALSE,
control = lmerControl(optimizer ="Nelder_Mead"))
return(fit1)
})
names(lmm_all) <- formula_vec
var_aic <- aictab(lmm_all, second.ord=TRUE, sort=TRUE) #rank based on AICc
r <- rsquared(lmm_all) #gives R^2 values for models. "Marginal" is the R^2 for just the fixed effects, "Conditional" is the R^2 for everything.
if(i == 1){
var_aic_sub <- var_aic[var_aic$Modnames == summary_mod_vars_all[[h]], ]
var_aic_null <- var_aic[var_aic$Modnames == summary_mod_null_all[[h]], ]
summary_models[,7][[h]] <- var_aic_sub$Delta_AICc - var_aic_null$Delta_AICc
} else if (i == 2) {
var_aic_sub <- var_aic[var_aic$Modnames == summary_mod_vars_sep[[h]], ]
var_aic_null <- var_aic[var_aic$Modnames == summary_mod_null_sep[[h]], ]
summary_models[,8][[h]] <- var_aic_sub$Delta_AICc - var_aic_null$Delta_AICc
} else if (i == 3){
var_aic_sub <- var_aic[var_aic$Modnames == summary_mod_vars_sep[[h]], ]
var_aic_null <- var_aic[var_aic$Modnames == summary_mod_null_sep[[h]], ]
summary_models[,9][[h]] <- var_aic_sub$Delta_AICc - var_aic_null$Delta_AICc
} else if (i == 4){
var_aic_sub <- var_aic[var_aic$Modnames == summary_mod_vars_sep[[h]], ]
var_aic_null <- var_aic[var_aic$Modnames == summary_mod_null_sep[[h]], ]
summary_models[,10][[h]] <- var_aic_sub$Delta_AICc - var_aic_null$Delta_AICc
}
View(summary_models)
write.csv(summary_models, "manuscript/results.csv", row.names=FALSE)
library(pointRes)
library(dplR)
library(data.table)
##to be clear, I wrote this code before I realized that some of the work done in these loops had already been done in the outputs of res.comp (specifically out.select). However, since the code runs well, and I double-checked that it was giving the same outputs as analyzing out.select, I'm keeping it as is.
##4a. canopy ####
dirs_can <- dir("data/core_files/canopy_cores", pattern = "_canopy.rwl")
dirs_can <- dirs_can[!dirs_can %in% c("frni_canopy.rwl", "frni_drop_canopy.rwl", "caco_drop_canopy.rwl")]
sp_can <- gsub("_drop_canopy.rwl", "", dirs_can)
canopy <- list()
widths_can <- list()
canopy_table <- NULL
for (i in seq(along=dirs_can)){
for (j in seq(along=sp_can)){
if (i==j){
file <- dirs_can[[i]]
rings <- read.rwl(paste0("data/core_files/canopy_cores/", file)) #read in rwl file
area <- bai.in(rings) #convert to bai.in
testr <- res.comp(area, nb.yrs=5, res.thresh.neg = 30, series.thresh = 50) #get resilience metrics
canopy[[i]] <- testr
widths_can[[i]] <- rings
testr_table <- data.frame(testr$out)
testr_table <- testr_table[testr_table$nb.series > 4, ] #remove where there are < 4 series
testr_table$sp <- sp_can[[j]]
testr_table$position <- "canopy"
canopy_table <- rbind(canopy_table, testr_table)
}
values <- paste0(sp_can, "_can_res")
names(canopy) <- values
values <- paste0(sp_can, "_canopy")
names(widths_can) <- values
##4b. subcanopy ####
dirs_subcan <- dir("data/core_files/subcanopy_cores", pattern = "_subcanopy.rwl")
#dirs_subcan <- dirs_subcan[dirs_subcan != "frni_drop_subcanopy.rwl" & dirs_subcan != "caco_drop_subcanopy.rwl"]
sp_subcan <- gsub("_drop_subcanopy.rwl", "", dirs_subcan)
subcanopy <- list()
widths_sub <- list()
subcanopy_table <- NULL
for (i in seq(along=dirs_subcan)){
for (j in seq(along=sp_subcan)){
if (i==j){
file <- dirs_subcan[[i]]
rings <- read.rwl(paste0("data/core_files/subcanopy_cores/", file)) #read in rwl file
area <- bai.in(rings) #convert to bai.in
test <- res.comp(area, nb.yrs=5, res.thresh.neg = 30, series.thresh = 50) #get resilience metrics
subcanopy[[i]] <- test
widths_sub[[i]] <- rings
test_table <- data.frame(test$out)
test_table <- test_table[test_table$nb.series > 4, ] #remove where there are < 4 series
test_table$sp <- sp_subcan[[j]]
test_table$position <- "subcanopy"
subcanopy_table <- rbind(subcanopy_table, test_table)
}
values_sub <- paste0(sp_subcan, "_subcan_res")
names(subcanopy) <- values_sub
values <- paste0(sp_subcan, "_subcanopy")
names(widths_sub) <- values
widths <- c(widths_can, widths_sub) #combine into one, then delete individual. For use in #5d
widths_can <- NULL
widths_subcan <- NULL
##4c. df for pointer years of all trees combined ####
full_ind <- rbind(canopy_table, subcanopy_table) #full table of indices for canopy and subcanopy cores
pointers <- full_ind[full_ind$nature == -1, ]
library(dplyr)
years_point <- count(pointers, vars=year) #counts the occurrences of each unique year
colnames(years_point) <- c("yr", "n.pointer")
years_point <- years_point[order(years_point$n.pointer, decreasing=TRUE), ]
#top drought years by species and canopy position
years_bysp <- pointers[pointers$year %in% c(1964, 1965, 1966, 1977, 1999), ]
years_bysp <- years_bysp[, c(1,13,14,2:12)]
years_bysp <- years_bysp[order(years_bysp$year, years_bysp$sp), ]
#write.csv(pointers, "data/occurrence_of_pointer_yrs.csv", row.names=FALSE)
##4d. resistance metrics for all trees ####
neil_list <- read.csv("data/core_list_for_neil.csv", stringsAsFactors = FALSE)
neil_list$tag <- paste0("X", neil_list$tag) #to match the colnames of can_resist below
# pointer_years <- head(years_point$yr) #from above in #4c
# pointer_years <- pointer_years[!pointer_years %in% c(1911, 1947, 1991)]
pointer_years <- c(1964, 1965, 1966, 1977, 1999)
# IMPORTANT: we are defining "1966" as the average of the resistance values over 1964, 1965, and 1966.
pointer_years_simple <- c(1966, 1977, 1999)
###canopy ####
#this loop says, for the different species in the list "canopy" (names(canopy)), create a dataframe of only the resistance index. Make a list of the colnames, which are the individual trees. Then, assign species identifiers for each one from Neil's core list, subset by the defined pointer years, and melt the data before rbinding.
tag_n <- names(canopy)
trees_canopy <- NULL
for (i in seq(along=1:length(tag_n))){
can_resist <- data.frame(canopy[[i]]$resist)
years <- rownames(can_resist)
colnames(can_resist) <- gsub("A", "", colnames(can_resist))
tree_series <- colnames(can_resist)
ind <- can_resist
ind_neil <- neil_list[neil_list$tag %in% tree_series, ]
ind$year <- years
ind$sp <- unique(ind_neil$sp)
ind$position <- "canopy"
ind <- ind[ind$year %in% pointer_years, ]
## these three lines of code are for taking the mean of 1964-1966,
## since it was a multi-year drought. We're calling it 1966 for simplicity.
ind["1966", 1:(ncol(ind) -3)] <- colMeans(ind[c(1:3), 1:(ncol(ind) -3)])
ind <- ind[-c(1,2), ]
ind[, 1:(ncol(ind) -3)] <- round(ind[, 1:(ncol(ind) -3)], 2)
change <- melt(ind)
setnames(change, old=c("variable", "value"), new=c("tree", "resist.value"))
change$tree <- gsub("X", "", change$tree)
change$tree <- gsub("^0", "", change$tree)
trees_canopy <- rbind(trees_canopy, change)
}
###subcanopy ####
#this loop says, for the different species in the list "subcanopy" (names(subcanopy)), create a dataframe of only the resistance index. Make a list of the colnames, which are the individual trees. Then, assign species identifiers for each one from Neil's core list, subset by the defined pointer years, and melt the data before rbinding.
tag_n <- names(subcanopy)
trees_subcanopy <- NULL
for (i in seq(along=1:length(tag_n))){
sub_resist <- data.frame(subcanopy[[i]]$resist)
years <- rownames(sub_resist)
colnames(sub_resist) <- gsub("A", "", colnames(sub_resist))
tree_series <- colnames(sub_resist)
ind <- sub_resist
ind_neil <- neil_list[neil_list$tag %in% tree_series, ]
ind$year <- years
ind$sp <- unique(ind_neil$sp)
ind$position <- "subcanopy"
ind <- ind[ind$year %in% pointer_years, ]
## these three lines of code are for taking the mean of 1964-1966,
## since it was a multi-year drought. We're calling it 1966 for simplicity.
ind["1966", 1:(ncol(ind) -3)] <- colMeans(ind[c(1:3), 1:(ncol(ind) -3)])
ind <- ind[-c(1,2), ]
ind[, 1:(ncol(ind) -3)] <- round(ind[, 1:(ncol(ind) -3)], 2)
change <- melt(ind)
setnames(change, old=c("variable", "value"), new=c("tree", "resist.value"))
change$tree <- gsub("X", "", change$tree)
change$tree <- gsub("^0", "", change$tree)
trees_subcanopy <- rbind(trees_subcanopy, change)
}
###rbind together ####
trees_all <- rbind(trees_canopy, trees_subcanopy)
trees_all$year <- as.numeric(trees_all$year)
#subset out NAs for resistance values (not necessary, bc lmm will automatically exclude them)
trees_all <- trees_all[!is.na(trees_all$resist.value), ]
trees_all$year <- as.character(trees_all$year)
library(SciViews) #for ln function
library(ggplot2)
library(rgdal) #to read in shapefiles
library(broom) #for the tidy function
library(sf) #for mapping
library(ggthemes) #for removing graticules when making pdf
library(rgeos) #for distance calculation
library(RCurl) #for reading in URLs
##5a. add in turgor loss point values ####
#add in tlp values (from Krista github issue #6 https://github.com/SCBI-ForestGEO/McGregor_climate-sensitivity-variation/issues/6)
turgor <- data.frame("sp" = c("cagl", "caovl", "fagr", "fram", "juni", "litu", "pist", "qual", "qupr", "quru", "quve", "caco", "cato", "frni"), "tlp" = c(-2.1282533, -2.24839333, -2.57164, -2.1012133, -2.75936, -1.9212933, NA, -2.58412, -2.3601733, -2.6395867, -2.3879067, -2.1324133, -2.31424, NA))
trees_all$tlp <- turgor$tlp[match(trees_all$sp, turgor$sp)]
#tlp for pist is NA. Removing pist (because of the tlp NA) gives different results.
#trees_all <- trees_all[!trees_all$sp == "pist", ]
tlp_test <- trees_all[!duplicated(trees_all$tree), ]
tlp_test$tree <- as.numeric(tlp_test$tree)
ggplot(data = tlp_test) +
aes(x = position, y = tlp) +
geom_boxplot(fill = "#0c4c8a") +
theme_minimal()
# facet_wrap(vars(year))
##5b. add in ring porosity qualifications ####
ring_porosity <- data.frame("sp" = c("cagl",  "caovl", "cato", "fagr", "fram", "juni",  "litu",  "pist",  "qual",  "qupr",  "quru",  "quve", "caco", "frni"), "rp" = c("ring", "ring", "ring", "diffuse", "ring", "semi-ring", "diffuse", NA, "ring", "ring", "ring", "ring", "ring", "ring"))
trees_all$rp <- ring_porosity$rp[match(trees_all$sp, ring_porosity$sp)]
#gives count of each rp value
rp_test <- trees_all[!duplicated(trees_all$tree), ]
rp_test$tree <- as.numeric(rp_test$tree)
ggplot(data = rp_test) +
aes(x = rp) +
geom_bar(fill = "#0c4c8a") +
theme_minimal() +
facet_wrap(vars(position))
##5c. add in elevation data ####
elev <- read.csv(text=getURL("https://raw.githubusercontent.com/SCBI-ForestGEO/SCBI-ForestGEO-Data/master/spatial_data/elevation/full_stem_elevation_2013.csv"))
trees_all$elev_m <- elev$dem_sigeo[match(trees_all$tree, elev$tag)]
##5d. add in distance to water ####
## mapping code here is taken from survey_maps.R in Dendrobands Rscripts folder.
## I have not found a way to make this not involve personal directories without moving all the data to my folder, which I'm hesitant about doing due to data redundancy.
scbi_plot <- readOGR("C:/Users/mcgregori/Dropbox (Smithsonian)/Github_Ian/SCBI-ForestGEO-Data/spatial_data/shapefiles/20m_grid.shp")
deer <- readOGR("C:/Users/mcgregori/Dropbox (Smithsonian)/Github_Ian/SCBI-ForestGEO-Data/spatial_data/shapefiles/deer_exclosure_2011.shp")
roads <- readOGR("C:/Users/mcgregori/Dropbox (Smithsonian)/Github_Ian/SCBI-ForestGEO-Data/spatial_data/shapefiles/SCBI_roads_edits.shp")
streams <- readOGR("C:/Users/mcgregori/Dropbox (Smithsonian)/Github_Ian/SCBI-ForestGEO-Data/spatial_data/shapefiles/SCBI_streams_edits.shp")
NS_divide <- readOGR("C:/Users/mcgregori/Dropbox (Smithsonian)/Github_Ian/Dendrobands/resources/maps/shapefiles/NS_divide1.shp")
#convert all shp to dataframe so that it can be used by ggplot
#if tidy isn't working, can also do: xxx_df <- as(xxx, "data.frame")
scbi_plot_df <- tidy(scbi_plot)
deer_df <- tidy(deer)
roads_df <- tidy(roads)
streams_df <- tidy(streams)
NS_divide_df <- tidy(NS_divide)
## now we get into code specific for this analysis
neil_map <- neil_list
neil_map$tag <- gsub("X", "", neil_map$tag)
neil_map$tag <- as.numeric(neil_map$tag)
neil_map <- neil_map[, c(1:6,23:24)]
map <- ggplot() +
geom_path(data = scbi_plot_df, aes(x = long, y = lat, group = group))+
geom_path(data=roads_df, aes(x=long, y=lat, group=group),
color="#996600", linetype=2)+
geom_path(data=streams_df, aes(x=long, y=lat, group=group), color="blue")+
geom_path(data=deer_df, aes(x=long, y=lat, group=group), size=1.1)+
geom_point(data=neil_map, aes(x=NAD83_X, y=NAD83_Y), shape=19)+
geom_text(data=neil_map, aes(x=NAD83_X, y=NAD83_Y, label=tag),
size=3, hjust=1.25, nudge_y=-1, nudge_x=1, check_overlap=TRUE)+
theme(plot.title=element_text(vjust=0.1))+
coord_sf(crs = "crs = +proj=merc", xlim=c(747350,747800), ylim=c(4308500, 4309125))
## calculating the distance requires some conversion. First, the points of the cored trees from neil_map must be in their own dataframe before they can be converted to a SpatialPoints object.
neil_map_sub <- neil_map[, c(7:8)]
neil_points <- SpatialPoints(neil_map_sub, proj4string = CRS(as.character("+proj=merc")))
## here, the minimum distance to water is calculated before binding with neil_map.
## A warning says that neil_points and streams are projected differently, but the output has been verified to be accurate.
distance_water <- data.frame(apply(gDistance(neil_points, streams, byid=TRUE), 2, min))
colnames(distance_water) <- "distance_water"
distance <- cbind(neil_map, distance_water)
## next, do a log transformation on the distances before adding as a column to trees_all (similar to the dbh calculations below)
distance$distance_ln <- ln(distance$distance_water)
trees_all$distance_ln <- distance$distance_ln[match(trees_all$tree, distance$tag)]
## this is to double check the accuracy of the map.
distance_short <- distance[distance$distance_water <= 30, ]
map <- ggplot() +
geom_path(data = scbi_plot_df, aes(x = long, y = lat, group = group))+
geom_path(data=roads_df, aes(x=long, y=lat, group=group),
color="#996600", linetype=2)+
geom_path(data=streams_df, aes(x=long, y=lat, group=group), color="blue")+
geom_path(data=deer_df, aes(x=long, y=lat, group=group), size=1.1)+
geom_point(data=distance_short, aes(x=NAD83_X, y=NAD83_Y), shape=19)+
geom_text(data=distance_short, aes(x=NAD83_X, y=NAD83_Y, label=tag),
size=3, hjust=1.25, nudge_y=-1, nudge_x=1, check_overlap=TRUE)+
theme(plot.title=element_text(vjust=0.1))+
coord_sf(crs = "crs = +proj=merc", xlim=c(747350,747800), ylim=c(4308500, 4309125))
##5e. add in dbh in each year 1999 ####
dbh <- trees_all[, c(1:4)]
dbh$dbh2013 <- elev$dbh[match(dbh$tree, elev$tag)]
#create df with bark thickness log values and intercept values from Krista's paper (supplemental info)
#https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/1365-2435.12470
#fagr does not have bark thickness measured because it is negligible
bark <- data.frame(
"sp" = c("acru", "fagr", "litu", "nysy", "caco", "cagl", "caovl", "cato", "fram", "juni", "qual", "qupr", "quru", "quve", "ulru"),
"bark_thick" = c(-2.564, 0, -0.659, -0.611, -1.917, -0.495, -2.504, -0.945, 0.318, -0.293, -1.231, -0.647, -0.789, 1.5, 1.133),
"intercept" = c(0.599, 0, 0.425, 0.413, 0.503, 0.316, 0.703, 0.396, 0.295, 0.385, 0.526, 0.423, 0.341, 0.053, -0.057))
dbh$bark_thick <- bark$bark_thick[match(dbh$sp, bark$sp)]
dbh$intercept <- bark$intercept[match(dbh$sp, bark$sp)]
#the main equation is based on ring widths. We have determined the equation to be
# rw(pointer_year) <- 0.5*dbh2013 - bark_thick*(dbh2013^intercept) - sum(rw(pointer_year):rw(end)). The first part of the equation is here. Summing the pointer years happens with the "q" df below in the loop.
dbh$rw_prelim <- (0.5*dbh$dbh2013) - (dbh$bark_thick*(dbh$dbh2013^dbh$intercept))
dbh$dbh_old <- "0" #in prep for below
dbh$dbh_old <- as.numeric(dbh$dbh_old)
for (i in seq(along=widths)){
df <- widths[[i]] #the list "widths" comes from #4a-4b
colnames(df) <- gsub("A", "", colnames(df)) #remove "A"
colnames(df) <- gsub("^0", "", colnames(df)) #remove leading 0
cols <- colnames(df) #define cols for below
colnames(df) <- gsub("^", "x", colnames(df)) #add "x" to make calling colnames below feasible
for (j in seq(along=cols)){
for (k in seq(along=colnames(df))){
ring_ind <- cols[[j]]
ring_col <- colnames(df)[[k]]
if(j==k){
#the output of this loop is 3 separate columns for each year's old dbh, hence why it is set to q as a dataframe before being combined below. Pointer_years_simple comes from #4d.
q <- data.frame(sapply(pointer_years_simple, function(x){
rw <- df[rownames(df)>=x, ]
ifelse(dbh$year == x & dbh$tree == ring_ind,
dbh$rw_prelim - sum(rw[, ring_col], na.rm=TRUE), 0)
}))
q$dbh_old <- q[,1] +q[,2] + q[,3] #add columns together
# q$dbh_old <- q[,1] +q[,2] + q[,3] + q[,4]
dbh$dbh_old <- dbh$dbh_old + q$dbh_old #combine with dbh
}
# check <- dbh[dbh$dbh_old == 0, ] #check if any tree was missed
trees_all$dbh_old <- dbh$dbh_old
trees_all$dbh_old <- ifelse(trees_all$dbh_old < 0, 0, trees_all$dbh_old)
trees_all$dbh_old <- ifelse(trees_all$dbh_old > 0, trees_all$dbh_old/10, trees_all$dbh_old)
trees_all$dbh_ln <- ifelse(trees_all$dbh_old == 0, NA, ln(trees_all$dbh_old))
##5f. add in tree heights ####
## taken from the canopy_heights script
trees_all$height_ln <- ifelse(trees_all$sp == "caco", (0.55+0.766*trees_all$dbh_ln),
ifelse(trees_all$sp == "cagl", (0.652+0.751*trees_all$dbh_ln),
ifelse(trees_all$sp == "caovl", (0.9+0.659*trees_all$dbh_ln),
ifelse(trees_all$sp == "cato", (0.879+0.668*trees_all$dbh_ln),
ifelse(trees_all$sp == "fagr", (0.513+0.712*trees_all$dbh_ln),
ifelse(trees_all$sp == "litu", (1.57+0.488*trees_all$dbh_ln),
ifelse(trees_all$sp == "quru", (1.13+0.54*trees_all$dbh_ln),
(0.849+0.659*trees_all$dbh_ln))))))))
##5g. remove all NAs ####
trees_all <- trees_all[complete.cases(trees_all), ]
##5h. remove resistance values >2 ####
trees_all <- trees_all[trees_all$resist.value <=2,]
##5i. make subsets for individual years, combine all to list ####
# x1964 <- trees_all[trees_all$year == 1964, ]
x1966 <- trees_all[trees_all$year == 1966, ]
x1977 <- trees_all[trees_all$year == 1977, ]
x1999 <- trees_all[trees_all$year == 1999, ]
model_df <- list(trees_all, x1966, x1977, x1999)
library(lme4)
library(AICcmodavg) #aictab function
library(car)
library(piecewiseSEM) #for R^2 values for all model outputs in a list
library(MuMIn) #for R^2 values of one model output
library(stringr)
##6a. Determine best model to use with AICc ####
## create table to store results
summary_models <- data.frame(
"prediction" = c("1.0", "1.1", "1.2a", "1.2b", "1.2c1, 1.3a1", "1.2c2", "1.3b1", "1.3a2", "1.3b2", "2.1", "2.2"),
"model_vars_all_years" =
c("resist.value ~ dbh_ln+year+(1|sp/tree)",
"resist.value ~ height_ln+year+(1|sp/tree)",
"resist.value ~ position+year+(1|sp/tree)",
"resist.value ~ position+height_ln+year+(1|sp/tree)",
"resist.value ~ elev_m+height_ln+year+(1|sp/tree)",
"resist.value ~ elev_m*height_ln+height_ln+year+(1|sp/tree)",
"resist.value ~ distance_ln+height_ln+year+(1|sp/tree)",
"resist.value ~ distance_ln*height_ln+height_ln+year+(1|sp/tree)",
"resist.value ~ tlp+height_ln+year+(1|sp/tree)",
"resist.value ~ rp+height_ln+year+(1|sp/tree)"),
"null_model_all_years" = NA,
"model_vars_sep_years" = NA,
"null_model_sep_years" = NA,
"response_direction" = c(NA, "-", "canopy<subcanopy", "canopy<subcanopy", "+", "+", "-", "+", "-", "-", "ring>diffuse"),
"dAIC_all_years" = NA,
"dAIC_1964-1966" = NA,
"dAIC_1977" = NA,
"dAIC_1999" = NA)
library(dplyr)
# change factor columns to character
summary_models %>% mutate_if(is.factor, as.character) -> summary_models
# fill in other columns
summary_models[c(1:3), 3] <- "resist.value ~ year+(1|sp/tree)"
summary_models[c(4:11), 3] <- "resist.value ~ height_ln+year+(1|sp/tree)"
summary_models$model_vars_sep_years <- gsub("year\\+|/tree", "", summary_models$model_vars_all_years)
summary_models$null_model_sep_years <- gsub("year\\+|/tree", "", summary_models$null_model_all_years)
#define vectors to be used in loop
summary_mod_vars_all <- summary_models$model_vars_all_years
summary_mod_vars_sep <- summary_models$model_vars_sep_years
summary_mod_null_all <- summary_models$null_model_all_years
summary_mod_null_sep <- summary_models$null_model_sep_years
##this loop goes through each mix of effects from each prediction (nrow(summary_models)), and runs those models for each of the datasets (all years and the three individual ones). For each iteration (44 total), it calculates dAIC (AIC of model with variable defined in model_vars columns minus the AIC of the null model).
for (i in seq_along(model_df)){
for (h in seq(along=summary_mod_vars_all)){
if (i==1){
#define response and effects
response <- gsub(" ~.*", "", summary_mod_vars_all[[h]])
effects <- unlist(strsplit(summary_mod_vars_all[[h]], "\\+|~ "))[-1]
# all fixed effects <- c("position", "tlp", "rp", "elev_m", "dbh_ln", "height_ln", "year")
#create all combinations of random / fixed effects
effects_comb <-
unlist( sapply( seq_len(length(effects)),
function(i) {
apply( combn(effects,i), 2, function(x) paste(x, collapse = "+"))
}))
# pair response with effect and sub out combinations that don't include random effects
#in general, if two variables are >70% correlated, you can toss one of them without significantly affecting the results
var_comb <- expand.grid(response, effects_comb)
var_comb <- var_comb[grepl("1", var_comb$Var2), ] #only keep in fixed/random combos
var_comb <- var_comb[grepl("year", var_comb$Var2), ] #keep year in for drought sake
} else {
#define response and effects
response <- gsub(" ~.*", "", summary_mod_vars_sep[[h]])
effects <- unlist(strsplit(summary_mod_vars_sep[[h]], "\\+|~ "))[-1]
# all fixed effects <- c("position", "tlp", "rp", "elev_m", "dbh_ln", "height_ln")
#create all combinations of random / fixed effects
effects_comb <-
unlist( sapply( seq_len(length(effects)),
function(i) {
apply( combn(effects,i), 2, function(x) paste(x, collapse = "+"))
}))
# pair response with effect and sub out combinations that don't include random effects
#in general, if two variables are >70% correlated, you can toss one of them without significantly affecting the results
var_comb <- expand.grid(response, effects_comb)
var_comb <- var_comb[grepl("1", var_comb$Var2), ] #only keep in fixed+random combos
}
# formulas for all combinations. $Var1 is the response, and $Var2 is the effect
# for good stats, you should have no more total parameters than 1/10th the number of observations in your dataset
formula_vec <- sprintf("%s ~ %s", var_comb$Var1, var_comb$Var2)
# create list of model outputs
lmm_all <- lapply(formula_vec, function(x){
fit1 <- lmer(x, data = model_df[[i]], REML=FALSE,
control = lmerControl(optimizer ="Nelder_Mead"))
return(fit1)
})
names(lmm_all) <- formula_vec
var_aic <- aictab(lmm_all, second.ord=TRUE, sort=TRUE) #rank based on AICc
r <- rsquared(lmm_all) #gives R^2 values for models. "Marginal" is the R^2 for just the fixed effects, "Conditional" is the R^2 for everything.
if(i == 1){
var_aic_sub <- var_aic[var_aic$Modnames == summary_mod_vars_all[[h]], ]
var_aic_null <- var_aic[var_aic$Modnames == summary_mod_null_all[[h]], ]
summary_models[,7][[h]] <- var_aic_sub$Delta_AICc - var_aic_null$Delta_AICc
} else if (i == 2) {
var_aic_sub <- var_aic[var_aic$Modnames == summary_mod_vars_sep[[h]], ]
var_aic_null <- var_aic[var_aic$Modnames == summary_mod_null_sep[[h]], ]
summary_models[,8][[h]] <- var_aic_sub$Delta_AICc - var_aic_null$Delta_AICc
} else if (i == 3){
var_aic_sub <- var_aic[var_aic$Modnames == summary_mod_vars_sep[[h]], ]
var_aic_null <- var_aic[var_aic$Modnames == summary_mod_null_sep[[h]], ]
summary_models[,9][[h]] <- var_aic_sub$Delta_AICc - var_aic_null$Delta_AICc
} else if (i == 4){
var_aic_sub <- var_aic[var_aic$Modnames == summary_mod_vars_sep[[h]], ]
var_aic_null <- var_aic[var_aic$Modnames == summary_mod_null_sep[[h]], ]
summary_models[,10][[h]] <- var_aic_sub$Delta_AICc - var_aic_null$Delta_AICc
}
warnings()
View(summary_models)
