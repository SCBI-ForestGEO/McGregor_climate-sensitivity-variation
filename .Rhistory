subcanopy_table <- NULL
for (i in seq(along=dirs_subcan)){
for (j in seq(along=sp_subcan)){
if (i==j){
file <- dirs_subcan[[i]]
rings <- read.rwl(paste0("data/core_files/subcanopy_cores/", file)) #read in rwl file
area <- bai.in(rings) #convert to bai.in
test <- res.comp(area, nb.yrs=5, res.thresh.neg = 30, series.thresh = 50) #get resilience metrics
subcanopy[[i]] <- test
widths_sub[[i]] <- rings
test_table <- data.frame(test$out)
test_table <- test_table[test_table$nb.series > 4, ] #remove where there are < 4 series
test_table$sp <- sp_subcan[[j]]
test_table$position <- "subcanopy"
subcanopy_table <- rbind(subcanopy_table, test_table)
}
values_sub <- paste0(sp_subcan, "_subcan_res")
names(subcanopy) <- values_sub
values <- paste0(sp_subcan, "_subcanopy")
names(widths_sub) <- values
widths <- c(widths_can, widths_sub) #combine into one, then delete individual. For use in #5d
widths_can <- NULL
widths_subcan <- NULL
##4c. df for pointer years of all trees combined ####
full_ind <- rbind(canopy_table, subcanopy_table) #full table of indices for canopy and subcanopy cores
pointers <- full_ind[full_ind$nature == -1, ]
library(dplyr)
years_point <- count(pointers, vars=year) #counts the occurrences of each unique year
colnames(years_point) <- c("yr", "n.pointer")
years_point <- years_point[order(years_point$n.pointer, decreasing=TRUE), ]
#top drought years by species and canopy position
years_bysp <- pointers[pointers$year %in% c(1964, 1965, 1966, 1977, 1999), ]
years_bysp <- years_bysp[, c(1,13,14,2:12)]
years_bysp <- years_bysp[order(years_bysp$year, years_bysp$sp), ]
#write.csv(pointers, "data/occurrence_of_pointer_yrs.csv", row.names=FALSE)
##4d. resistance metrics for all trees ####
neil_list <- read.csv("data/core_list_for_neil.csv", stringsAsFactors = FALSE)
neil_list$tag <- paste0("X", neil_list$tag) #to match the colnames of can_resist below
# pointer_years <- head(years_point$yr) #from above in #4c
# pointer_years <- pointer_years[!pointer_years %in% c(1911, 1947, 1991)]
pointer_years <- c(1964, 1965, 1966, 1977, 1999)
# IMPORTANT: we are defining "1966" as the average of the resistance values over 1964, 1965, and 1966.
pointer_years_simple <- c(1966, 1977, 1999)
###canopy ####
#this loop says, for the different species in the list "canopy" (names(canopy)), create a dataframe of only the resistance index. Make a list of the colnames, which are the individual trees. Then, assign species identifiers for each one from Neil's core list, subset by the defined pointer years, and melt the data before rbinding.
tag_n <- names(canopy)
trees_canopy <- NULL
for (i in seq(along=1:length(tag_n))){
can_resist <- data.frame(canopy[[i]]$resist)
years <- rownames(can_resist)
colnames(can_resist) <- gsub("A", "", colnames(can_resist))
tree_series <- colnames(can_resist)
ind <- can_resist
ind_neil <- neil_list[neil_list$tag %in% tree_series, ]
ind$year <- years
ind$sp <- unique(ind_neil$sp)
ind$position <- "canopy"
ind <- ind[ind$year %in% pointer_years, ]
## these three lines of code are for taking the mean of 1964-1966,
## since it was a multi-year drought. We're calling it 1966 for simplicity.
ind["1966", 1:(ncol(ind) -3)] <- colMeans(ind[c(1:3), 1:(ncol(ind) -3)])
ind <- ind[-c(1,2), ]
ind[, 1:(ncol(ind) -3)] <- round(ind[, 1:(ncol(ind) -3)], 2)
change <- melt(ind)
setnames(change, old=c("variable", "value"), new=c("tree", "resist.value"))
change$tree <- gsub("X", "", change$tree)
change$tree <- gsub("^0", "", change$tree)
trees_canopy <- rbind(trees_canopy, change)
}
###subcanopy ####
#this loop says, for the different species in the list "subcanopy" (names(subcanopy)), create a dataframe of only the resistance index. Make a list of the colnames, which are the individual trees. Then, assign species identifiers for each one from Neil's core list, subset by the defined pointer years, and melt the data before rbinding.
tag_n <- names(subcanopy)
trees_subcanopy <- NULL
for (i in seq(along=1:length(tag_n))){
sub_resist <- data.frame(subcanopy[[i]]$resist)
years <- rownames(sub_resist)
colnames(sub_resist) <- gsub("A", "", colnames(sub_resist))
tree_series <- colnames(sub_resist)
ind <- sub_resist
ind_neil <- neil_list[neil_list$tag %in% tree_series, ]
ind$year <- years
ind$sp <- unique(ind_neil$sp)
ind$position <- "subcanopy"
ind <- ind[ind$year %in% pointer_years, ]
## these three lines of code are for taking the mean of 1964-1966,
## since it was a multi-year drought. We're calling it 1966 for simplicity.
ind["1966", 1:(ncol(ind) -3)] <- colMeans(ind[c(1:3), 1:(ncol(ind) -3)])
ind <- ind[-c(1,2), ]
ind[, 1:(ncol(ind) -3)] <- round(ind[, 1:(ncol(ind) -3)], 2)
change <- melt(ind)
setnames(change, old=c("variable", "value"), new=c("tree", "resist.value"))
change$tree <- gsub("X", "", change$tree)
change$tree <- gsub("^0", "", change$tree)
trees_subcanopy <- rbind(trees_subcanopy, change)
}
###rbind together ####
trees_all <- rbind(trees_canopy, trees_subcanopy)
trees_all$year <- as.numeric(trees_all$year)
#subset out NAs for resistance values (not necessary, bc lmm will automatically exclude them)
trees_all <- trees_all[!is.na(trees_all$resist.value), ]
trees_all$year <- as.character(trees_all$year)
library(SciViews) #for ln function
library(ggplot2)
library(rgdal) #to read in shapefiles
library(broom) #for the tidy function
library(sf) #for mapping
library(ggthemes) #for removing graticules when making pdf
library(rgeos) #for distance calculation
library(RCurl) #for reading in URLs
##5a. add in turgor loss point values ####
#add in tlp values (from Krista github issue #6 https://github.com/SCBI-ForestGEO/McGregor_climate-sensitivity-variation/issues/6)
turgor <- data.frame("sp" = c("cagl", "caovl", "fagr", "fram", "juni", "litu", "pist", "qual", "qupr", "quru", "quve", "caco", "cato", "frni"), "tlp" = c(-2.1282533, -2.24839333, -2.57164, -2.1012133, -2.75936, -1.9212933, NA, -2.58412, -2.3601733, -2.6395867, -2.3879067, -2.1324133, -2.31424, NA))
trees_all$tlp <- turgor$tlp[match(trees_all$sp, turgor$sp)]
#tlp for pist is NA. Removing pist (because of the tlp NA) gives different results.
#trees_all <- trees_all[!trees_all$sp == "pist", ]
tlp_test <- trees_all[!duplicated(trees_all$tree), ]
tlp_test$tree <- as.numeric(tlp_test$tree)
ggplot(data = tlp_test) +
aes(x = position, y = tlp) +
geom_boxplot(fill = "#0c4c8a") +
theme_minimal()
# facet_wrap(vars(year))
##5b. add in ring porosity qualifications ####
ring_porosity <- data.frame("sp" = c("cagl",  "caovl", "cato", "fagr", "fram", "juni",  "litu",  "pist",  "qual",  "qupr",  "quru",  "quve", "caco", "frni"), "rp" = c("ring", "ring", "ring", "diffuse", "ring", "semi-ring", "diffuse", NA, "ring", "ring", "ring", "ring", "ring", "ring"))
trees_all$rp <- ring_porosity$rp[match(trees_all$sp, ring_porosity$sp)]
#gives count of each rp value
rp_test <- trees_all[!duplicated(trees_all$tree), ]
rp_test$tree <- as.numeric(rp_test$tree)
ggplot(data = rp_test) +
aes(x = rp) +
geom_bar(fill = "#0c4c8a") +
theme_minimal() +
facet_wrap(vars(position))
##5c. add in elevation data ####
elev <- read.csv(text=getURL("https://raw.githubusercontent.com/SCBI-ForestGEO/SCBI-ForestGEO-Data/master/spatial_data/elevation/full_stem_elevation_2013.csv"))
trees_all$elev_m <- elev$dem_sigeo[match(trees_all$tree, elev$tag)]
##5d. add in distance to water ####
## mapping code here is taken from survey_maps.R in Dendrobands Rscripts folder.
## I have not found a way to make this not involve personal directories without moving all the data to my folder, which I'm hesitant about doing due to data redundancy.
scbi_plot <- readOGR("C:/Users/mcgregori/Dropbox (Smithsonian)/Github_Ian/SCBI-ForestGEO-Data/spatial_data/shapefiles/20m_grid.shp")
deer <- readOGR("C:/Users/mcgregori/Dropbox (Smithsonian)/Github_Ian/SCBI-ForestGEO-Data/spatial_data/shapefiles/deer_exclosure_2011.shp")
roads <- readOGR("C:/Users/mcgregori/Dropbox (Smithsonian)/Github_Ian/SCBI-ForestGEO-Data/spatial_data/shapefiles/SCBI_roads_edits.shp")
streams <- readOGR("C:/Users/mcgregori/Dropbox (Smithsonian)/Github_Ian/SCBI-ForestGEO-Data/spatial_data/shapefiles/SCBI_streams_edits.shp")
NS_divide <- readOGR("C:/Users/mcgregori/Dropbox (Smithsonian)/Github_Ian/Dendrobands/resources/maps/shapefiles/NS_divide1.shp")
#convert all shp to dataframe so that it can be used by ggplot
#if tidy isn't working, can also do: xxx_df <- as(xxx, "data.frame")
scbi_plot_df <- tidy(scbi_plot)
deer_df <- tidy(deer)
roads_df <- tidy(roads)
streams_df <- tidy(streams)
NS_divide_df <- tidy(NS_divide)
## now we get into code specific for this analysis
neil_map <- neil_list
neil_map$tag <- gsub("X", "", neil_map$tag)
neil_map$tag <- as.numeric(neil_map$tag)
neil_map <- neil_map[, c(1:6,23:24)]
map <- ggplot() +
geom_path(data = scbi_plot_df, aes(x = long, y = lat, group = group))+
geom_path(data=roads_df, aes(x=long, y=lat, group=group),
color="#996600", linetype=2)+
geom_path(data=streams_df, aes(x=long, y=lat, group=group), color="blue")+
geom_path(data=deer_df, aes(x=long, y=lat, group=group), size=1.1)+
geom_point(data=neil_map, aes(x=NAD83_X, y=NAD83_Y), shape=19)+
geom_text(data=neil_map, aes(x=NAD83_X, y=NAD83_Y, label=tag),
size=3, hjust=1.25, nudge_y=-1, nudge_x=1, check_overlap=TRUE)+
theme(plot.title=element_text(vjust=0.1))+
coord_sf(crs = "crs = +proj=merc", xlim=c(747350,747800), ylim=c(4308500, 4309125))
## calculating the distance requires some conversion. First, the points of the cored trees from neil_map must be in their own dataframe before they can be converted to a SpatialPoints object.
neil_map_sub <- neil_map[, c(7:8)]
neil_points <- SpatialPoints(neil_map_sub, proj4string = CRS(as.character("+proj=merc")))
## here, the minimum distance to water is calculated before binding with neil_map.
## A warning says that neil_points and streams are projected differently, but the output has been verified to be accurate.
distance_water <- data.frame(apply(gDistance(neil_points, streams, byid=TRUE), 2, min))
colnames(distance_water) <- "distance_water"
distance <- cbind(neil_map, distance_water)
## next, do a log transformation on the distances before adding as a column to trees_all (similar to the dbh calculations below)
distance$distance_ln <- ln(distance$distance_water)
trees_all$distance_ln <- distance$distance_ln[match(trees_all$tree, distance$tag)]
## this is to double check the accuracy of the map.
distance_short <- distance[distance$distance_water <= 30, ]
map <- ggplot() +
geom_path(data = scbi_plot_df, aes(x = long, y = lat, group = group))+
geom_path(data=roads_df, aes(x=long, y=lat, group=group),
color="#996600", linetype=2)+
geom_path(data=streams_df, aes(x=long, y=lat, group=group), color="blue")+
geom_path(data=deer_df, aes(x=long, y=lat, group=group), size=1.1)+
geom_point(data=distance_short, aes(x=NAD83_X, y=NAD83_Y), shape=19)+
geom_text(data=distance_short, aes(x=NAD83_X, y=NAD83_Y, label=tag),
size=3, hjust=1.25, nudge_y=-1, nudge_x=1, check_overlap=TRUE)+
theme(plot.title=element_text(vjust=0.1))+
coord_sf(crs = "crs = +proj=merc", xlim=c(747350,747800), ylim=c(4308500, 4309125))
##5e. add in dbh for each year ####
###original method ####
# dbh <- trees_all[, c(1:4)]
# dbh$dbh2013 <- elev$dbh[match(dbh$tree, elev$tag)]
#
# #create df with bark thickness log values and intercept values from Krista's paper (supplemental info)
# #https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/1365-2435.12470
# #fagr does not have bark thickness measured because it is negligible
# bark <- data.frame(
#   "sp" = c("acru", "fagr", "litu", "nysy", "caco", "cagl", "caovl", "cato", "fram", "juni", "qual", "qupr", "quru", "quve", "ulru"),
#   "bark_thick_ln" = c(-2.564, 0, -0.659, -0.611, -1.917, -0.495, -2.504, -0.945, 0.318, -0.293, -1.231, -0.647, -0.789, 1.5, 1.133),
#   "intercept" = c(0.599, 0, 0.425, 0.413, 0.503, 0.316, 0.703, 0.396, 0.295, 0.385, 0.526, 0.423, 0.341, 0.053, -0.057))
#
# bark$bark_thick <- ifelse(bark$bark_thick_ln != 0, exp(bark$bark_thick_ln), bark$bark_thick_ln)
#
# bark$bark_thick <- exp(bark$bark_thick_ln)
#
# dbh$bark_thick <- bark$bark_thick[match(dbh$sp, bark$sp)]
# dbh$intercept <- bark$intercept[match(dbh$sp, bark$sp)]
#
# #the main equation is based on ring widths. We have determined the equation to be
# # rw(pointer_year) <- 0.5*dbh2013 - bark_thick*(dbh2013^intercept) - sum(rw(pointer_year):rw(end)). The first part of the equation is here. Summing the pointer years happens with the "q" df below in the loop.
# dbh$rw_prelim <- (0.5*dbh$dbh2013) - (dbh$bark_thick*(dbh$dbh2013^dbh$intercept))
#
# dbh$dbh_old <- "0" #in prep for below
# dbh$dbh_old <- as.numeric(dbh$dbh_old)
#
# for (i in seq(along=widths)){
#   df <- widths[[i]] #the list "widths" comes from #4a-4b
#   colnames(df) <- gsub("A", "", colnames(df)) #remove "A"
#   colnames(df) <- gsub("^0", "", colnames(df)) #remove leading 0
#
#   cols <- colnames(df) #define cols for below
#   colnames(df) <- gsub("^", "x", colnames(df)) #add "x" to make calling colnames below feasible
#
#   for (j in seq(along=cols)){
#     for (k in seq(along=colnames(df))){
#       ring_ind <- cols[[j]]
#       ring_col <- colnames(df)[[k]]
#
#       if(j==k){
#         #the output of this loop is 3 separate columns for each year's old dbh, hence why it is set to q as a dataframe before being combined below. Pointer_years_simple comes from #4d.
#         q <- data.frame(sapply(pointer_years_simple, function(x){
#           rw <- df[rownames(df)>=x, ]
#           ifelse(dbh$year == x & dbh$tree == ring_ind,
#                  dbh$rw_prelim - sum(rw[, ring_col], na.rm=TRUE), 0)
#         }))
#
#         q$dbh_old <- q[,1] +q[,2] + q[,3] #add columns together
#         # q$dbh_old <- q[,1] +q[,2] + q[,3] + q[,4]
#         dbh$dbh_old <- dbh$dbh_old + q$dbh_old #combine with dbh
#       }
#     }
#   }
# }
#
# # check <- dbh[dbh$dbh_old == 0, ] #check if any tree was missed
#
# trees_all$dbh_old <- dbh$dbh_old
# trees_all$dbh_old <- ifelse(trees_all$dbh_old < 0, 0, trees_all$dbh_old)
# trees_all$dbh_old <- ifelse(trees_all$dbh_old > 0, trees_all$dbh_old/10, trees_all$dbh_old)
# trees_all$dbh_ln <- ifelse(trees_all$dbh_old == 0, NA, ln(trees_all$dbh_old))
###new method ####
#steps to calculate old dbh
bark <- read.csv("data/SCBI_bark_depth.csv")
bark <- bark[bark$species %in% sp_can | bark$species %in% sp_subcan, ]
#1. Calculate diameter_nobark for 2008 = DBH.mm.2008-2*bark.depth.mm
bark$diam_nobark_2008 <- bark$DBH.mm.2008 - 2*bark$bark.depth.mm
#2. ln-transform both diam_nobark_2008 (x) and bark.depth.mm (y)
#3. Fit a linear model, and use model to predict ln(bark.depth.mm)
library(devtools)
source_gist("524eade46135f6348140")
ggplot(data = bark, aes(x = ln(diam_nobark_2008^2), y = ln(bark.depth.mm), label = ln(bark.depth.mm))) +
stat_smooth_func(geom="text",method="lm",hjust=0.16, vjust=-1,parse=TRUE) +
geom_smooth(method="lm", se=FALSE, color="black") +
geom_point(color = "#0c4c8a") +
theme_minimal() +
facet_wrap(vars(species))
ggplot(data = bark, aes(x = ln(diam_nobark_2008^2), y = ln(bark.depth.mm), label = ln(bark.depth.mm))) +
stat_smooth_func(geom="text",method="lm",hjust=0.16, vjust=-1,parse=TRUE) +
geom_smooth(method="lm", se=FALSE, color="black") +
geom_point(color = "#0c4c8a") +
theme_minimal()
bark$predict_barkthick_ln <- NA
bark$predict_barkthick_ln <-
ifelse(bark$species == "caco", -1.56+0.416*ln(bark$diam_nobark_2008),
ifelse(bark$species == "cagl", -0.393+0.268*ln(bark$diam_nobark_2008),
ifelse(bark$species == "caovl", -2.18+0.651*ln(bark$diam_nobark_2008),
ifelse(bark$species == "cato", -0.477+0.301*ln(bark$diam_nobark_2008),
ifelse(bark$species == "fram", 0.418+0.268*ln(bark$diam_nobark_2008),
ifelse(bark$species == "juni", 0.346+0.279*ln(bark$diam_nobark_2008),
ifelse(bark$species == "litu", -1.14+0.463*ln(bark$diam_nobark_2008),
ifelse(bark$species == "qual", -2.09+0.637*ln(bark$diam_nobark_2008),
ifelse(bark$species == "qupr", -1.31+0.528*ln(bark$diam_nobark_2008),
ifelse(bark$species == "quru", -0.593+0.292*ln(bark$diam_nobark_2008),
ifelse(bark$species == "quve", 0.245+0.219*ln(bark$diam_nobark_2008),
bark$predict_barkthick_ln)))))))))))
#4. Take exponent of bark.depth.mm and make sure predicted values look good.
bark$predict_barkthick <- exp(bark$predict_barkthick_ln)
range(bark$predict_barkthick - bark$bark.depth.mm)
#5. Get mean bark thickness per species in 2008.
## The equation for calculating old dbh, using 1999 as an example, is
## dbh1999 = dbh2008 - 2(ring.width2013 - ring.width1999) - 2(bark.depth2008) + 2(bark.depth1999)
## using the dataset from calculating the regression equations, we can get mean bark thickness per species in 2008.
##set up dbh dataframe
dbh <- trees_all[, c(1:4)]
scbi.stem1 <- read.csv(text=getURL("https://raw.githubusercontent.com/SCBI-ForestGEO/SCBI-ForestGEO-Data/master/tree_main_census/data/census-csv-files/scbi.stem1.csv"))
dbh$dbh2008 <- scbi.stem1$dbh[match(dbh$tree, scbi.stem1$tag)]
mean_bark <- aggregate(bark$bark.depth.mm, by=list(bark$species), mean)
colnames(mean_bark) <- c("sp", "mean_bark_2008")
dbh$mean_bark_2008 <- ifelse(dbh$sp %in% mean_bark$sp, mean_bark$mean_bark_2008[match(dbh$sp, mean_bark$sp)], mean(bark$bark.depth.mm))
dbh$mean_bark_2008 <- round(dbh$mean_bark_2008, 2)
#6.Thus, the only value we're missing is bark depth in 1999.
## This is ok, because we can calculate from the regression equation per each species (all we need is diam_nobark_1999).Calculate diam_nobark_1999 using
## diam_nobark_1999 = dbh2008 - 2*(bark.depth2008) - 2*(sum(ring.width1999:ring.width2008))
##define this column before loop
dbh$diam_nobark_old <- 0
for (i in seq(along=widths)){
df <- widths[[i]] #the list "widths" comes from #4a-4b
colnames(df) <- gsub("A", "", colnames(df)) #remove "A"
colnames(df) <- gsub("^0", "", colnames(df)) #remove leading 0
cols <- colnames(df) #define cols for below
colnames(df) <- gsub("^", "x", colnames(df)) #add "x" to make calling colnames below feasible
for (j in seq(along=cols)){
for (k in seq(along=colnames(df))){
ring_ind <- cols[[j]]
ring_col <- colnames(df)[[k]]
if(j==k){
#the output of this loop is 3 separate columns for each year's old dbh, hence why it is set to q as a dataframe before being combined below. Pointer_years_simple comes from #4d.
q <- data.frame(sapply(pointer_years_simple, function(x){
rw <- df[rownames(df)>=x, ]
ifelse(dbh$year == x & dbh$tree == ring_ind,
dbh$dbh2008 - 2*(dbh$mean_bark_2008) - sum(rw[rownames(rw) %in% c(x:2008), ring_col], na.rm=TRUE), 0)
}))
q$diam_nobark_old <- q[,1] +q[,2] + q[,3] #add columns together
# q$dbh_old <- q[,1] +q[,2] + q[,3] + q[,4]
dbh$diam_nobark_old <- dbh$diam_nobark_old + q$diam_nobark_old #combine with dbh (it's the same order of rows)
}
#7. Calculate bark thickness using regression equation per appropriate sp
## ln(bark.depth.1999) = intercept + ln(diam_nobark)*constant
## bark.depth.1999 = exp(ln(bark.depth.1999))
#the full equation at the bottom is the regression equation for all these species put together. "fagr" is given a bark thickness of 0 because it is negligble
dbh$bark_thick_old_ln <- NA
dbh$bark_thick_old_ln <- ifelse(dbh$sp == "caco", -1.56+0.416*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "cagl", -0.393+0.268*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "caovl", -2.18+0.651*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "cato", -0.477+0.301*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "fram", 0.418+0.268*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "juni", 0.346+0.279*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "litu", -1.14+0.463*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "qual", -2.09+0.637*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "qupr", -1.31+0.528*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "quru", -0.593+0.292*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "quve", 0.245+0.219*ln(dbh$diam_nobark_old),
ifelse(dbh$sp == "fagr", 0,
-1.01+0.213*ln(dbh$diam_nobark_old)))))))))))))
dbh$bark_thick_old <- ifelse(dbh$sp == "fagr", 0, exp(dbh$bark_thick_old_ln))
#8. Add to soluation frmo #6 to get full dbh1999
## dbh1999 = diam_nobark_1999 + 2*bark.depth.1999
dbh$dbh_old <- dbh$diam_nobark_old + 2*dbh$bark_thick_old
##NOTE
##The first time I ran this code I was getting NaNs for one tree (140939), because the dbh in 2008 was listed as 16.9. I double-checked this, and that was the second stem, which we obviously didn't core at 1.69 cm (or 2.2 cm in 2013). The dbh is meant to be the first stem. However, there was confusion with the dbh in the field and
trees_all$dbh_old <- dbh$dbh_old[match(trees_all$tree, dbh$tree)]
trees_all$dbh_ln <- ln(trees_all$dbh_old)
##5f. add in ratio of sapwood area to total wood ####
#get radius.w/o.bark mm and convert to cm for ratio further down
dbh$radius_nobark <- dbh$diam_nobark_old/2
dbh$radius_nobark <- dbh$radius_nobark/10
#area without bark = (pi*radius.w/o.bark)^2 (cm^2)
dbh$area_nobark <- pi*(dbh$radius_nobark)^2
#calculate sapwood area
##sapwood area = tree area (minus bark) - heartwood area
sap <- read.csv("data/SCBI_Sapwood_Data.csv", stringsAsFactors = FALSE)
sap <- sap[,c(1:5,8:10,24)]
sap$sp <- paste0(gsub("^(..).*", "\\1", sap$Latin),
gsub("^.* (..).*", "\\1", sap$Latin))
sap$sp <- tolower(sap$sp)
##subtract bark thickness from dbh
##NOTE bark thickness is from 2008, even tho sap data collected 2010
sap$dbh_nobark <- 0
for (i in seq(along=mean_bark$mean_bark_2008)){
sub <- mean_bark[mean_bark$mean_bark_2008[[i]] == mean_bark$mean_bark_2008, ]
sap$dbh_nobark <- ifelse(sap$sp == sub$sp, sap$DBH-sub$mean_bark_2008, sap$dbh_nobark)
}
#heartwood radius = 0.5*dbh – sapwood depth (mm)
sap$hw_rad <- 0.5*sap$dbh_nobark - sap$sapwood.depth..mm.
#Heartwood area = pi*(heartwood radius)^2 (mm^2)
sap$hw_area <- pi*(sap$hw_rad)^2
#Sapwood area = pi*((0.5*dbh)^2) – heartwood area
sap$sap_area <- pi*(0.5*sap$dbh_nobark)^2 - sap$hw_area
sap$sap_area <- sap$sap_area/100
sap <- sap[sap$sp %in% sp_can | sap$sp %in% sp_subcan, ]
library(devtools)
source_gist("524eade46135f6348140")
ggplot(data = sap, aes(x = ln(DBH), y = ln(sap_area), label = ln(sap_area))) +
stat_smooth_func(geom="text",method="lm",hjust=0.16, vjust=-1,parse=TRUE) +
geom_smooth(method="lm", se=FALSE, color="black") +
geom_point(color = "#0c4c8a") +
theme_minimal() +
facet_wrap(vars(sp))
ggplot(data = sap, aes(x = ln(DBH), y = ln(sap_area), label = ln(sap_area))) +
stat_smooth_func(geom="text",method="lm",hjust=0.16, vjust=-1,parse=TRUE) +
geom_smooth(method="lm", se=FALSE, color="black") +
geom_point(color = "#0c4c8a") +
theme_minimal()
#the bottom equation is the total regression equation
dbh$sapwood_area_ln <- NA
dbh$sapwood_area_ln <- ifelse(dbh$sp == "caco", -3.41+1.6*ln(dbh$dbh_old),
ifelse(dbh$sp == "cagl", -4.34+1.77*ln(dbh$dbh_old),
ifelse(dbh$sp == "cato", -3.14+1.59*ln(dbh$dbh_old),
ifelse(dbh$sp == "fram", -7.75+2.4*ln(dbh$dbh_old),
ifelse(dbh$sp == "juni", -4.23+1.64*ln(dbh$dbh_old),
ifelse(dbh$sp == "litu", -5.5+1.98*ln(dbh$dbh_old),
ifelse(dbh$sp == "qual", -2.66+1.35*ln(dbh$dbh_old),
ifelse(dbh$sp == "qupr", -4.89+1.76*ln(dbh$dbh_old),
ifelse(dbh$sp == "quru", -5.35+1.74*ln(dbh$dbh_old),
ifelse(dbh$sp == "quve", -4.57+1.63*ln(dbh$dbh_old),
-3.13+1.5*ln(dbh$dbh_old)))))))))))
dbh$sapwood_area <- exp(dbh$sapwood_area_ln)
#ratio = sapwood area:area without bark
dbh$sap_ratio <- dbh$sapwood_area/dbh$area_nobark
trees_all$sap_ratio <- dbh$sap_ratio[match(trees_all$tree, dbh$tree)]
##5g. add in tree heights ####
## taken from the canopy_heights script
trees_all$height_ln <- ifelse(trees_all$sp == "caco", (0.55+0.766*trees_all$dbh_ln),
ifelse(trees_all$sp == "cagl", (0.652+0.751*trees_all$dbh_ln),
ifelse(trees_all$sp == "caovl", (0.9+0.659*trees_all$dbh_ln),
ifelse(trees_all$sp == "cato", (0.879+0.668*trees_all$dbh_ln),
ifelse(trees_all$sp == "fagr", (0.513+0.712*trees_all$dbh_ln),
ifelse(trees_all$sp == "litu", (1.57+0.488*trees_all$dbh_ln),
ifelse(trees_all$sp == "quru", (1.13+0.54*trees_all$dbh_ln),
(0.849+0.659*trees_all$dbh_ln))))))))
trees_all$height <- exp(trees_all$height_ln)
##5h. add in all crown positions ####
positions <- read.csv(text=getURL("https://raw.githubusercontent.com/SCBI-ForestGEO/SCBI-ForestGEO-Data/master/tree_dimensions/tree_crowns/cored_dendroband_crown_position_data/dendro_cored_full.csv"))
trees_all$position_all <- positions$crown.position[match(trees_all$tree, positions$tag)]
trees_all$position_all <- gsub("D", "dominant", trees_all$position_all)
trees_all$position_all <- gsub("C", "co-dominant", trees_all$position_all)
trees_all$position_all <- gsub("I", "intermediate", trees_all$position_all)
trees_all$position_all <- gsub("S", "suppressed", trees_all$position_all)
#this has been proven to be roughly equivalent to position_all, so we're sticking with position_all
# trees_all$illum <- positions$illum[match(trees_all$tree, positions$tag)]
# trees_all$illum <- as.character(trees_all$illum)
#this csv has avg/min/max dbh for each canopy position by sp
# positionsp <- read.csv("data/core_chronologies_by_crownposition.csv")
##5i. remove all NAs and one bad tree ####
trees_all <- trees_all[complete.cases(trees_all), ]
##fram 140939 has been mislabeled. It is recorded as having a small dbh when that is the second stem. In terms of canopy position, though, it fell between time of coring and when positions were recorded, thus we do not know its position.
trees_all <- trees_all[!trees_all$tree == 140939, ]
##5j. remove resistance values >2 ####
trees_all <- trees_all[trees_all$resist.value <=2,]
##5k. make subsets for individual years, combine all to list ####
# x1964 <- trees_all[trees_all$year == 1964, ]
x1966 <- trees_all[trees_all$year == 1966, ]
x1977 <- trees_all[trees_all$year == 1977, ]
x1999 <- trees_all[trees_all$year == 1999, ]
model_df <- list(trees_all, x1966, x1977, x1999)
response <- "resist.value"
effects <- c("position_all", "sap_ratio", "tlp", "rp", "elev_m", "height_ln", "year", "(1|sp/tree)")
#create all combinations of random / fixed effects
effects_comb <-
unlist( sapply( seq_len(length(effects)),
function(i) {
apply( combn(effects,i), 2, function(x) paste(x, collapse = "+"))
}))
# pair response with effect and sub out combinations that don't include random effects
#in general, if two variables are >70% correlated, you can toss one of them without significantly affecting the results
var_comb <- expand.grid(response, effects_comb)
var_comb <- var_comb[grepl("1", var_comb$Var2), ] #only keep in fixed/random combos
var_comb <- var_comb[grepl("year", var_comb$Var2), ] #keep year in for drought sake
# formulas for all combinations. $Var1 is the response, and $Var2 is the effect
# for good stats, you should have no more total parameters than 1/10th the number of observations in your dataset
formula_vec <- sprintf("%s ~ %s", var_comb$Var1, var_comb$Var2)
# create list of model outputs
lmm_all <- lapply(formula_vec, function(x){
fit1 <- lmer(x, data = trees_all, REML=FALSE,
control = lmerControl(optimizer ="Nelder_Mead"))
return(fit1)
})
names(lmm_all) <- formula_vec
var_aic <- aictab(lmm_all, second.ord=TRUE, sort=TRUE) #rank based on AICc
r <- rsquared(lmm_all) #gives R^2 values for models. "Marginal" is the R^2 for just the fixed effects, "Conditional" is the R^2 for everything.
library(lme4)
library(AICcmodavg) #aictab function
library(car)
library(piecewiseSEM) #for R^2 values for all model outputs in a list
library(MuMIn) #for R^2 values of one model output
library(stringr)
library(dplyr)
response <- "resist.value"
effects <- c("position_all", "sap_ratio", "tlp", "rp", "elev_m", "height_ln", "year", "(1|sp/tree)")
#create all combinations of random / fixed effects
effects_comb <-
unlist( sapply( seq_len(length(effects)),
function(i) {
apply( combn(effects,i), 2, function(x) paste(x, collapse = "+"))
}))
# pair response with effect and sub out combinations that don't include random effects
#in general, if two variables are >70% correlated, you can toss one of them without significantly affecting the results
var_comb <- expand.grid(response, effects_comb)
var_comb <- var_comb[grepl("1", var_comb$Var2), ] #only keep in fixed/random combos
var_comb <- var_comb[grepl("year", var_comb$Var2), ] #keep year in for drought sake
# formulas for all combinations. $Var1 is the response, and $Var2 is the effect
# for good stats, you should have no more total parameters than 1/10th the number of observations in your dataset
formula_vec <- sprintf("%s ~ %s", var_comb$Var1, var_comb$Var2)
# create list of model outputs
lmm_all <- lapply(formula_vec, function(x){
fit1 <- lmer(x, data = trees_all, REML=FALSE,
control = lmerControl(optimizer ="Nelder_Mead"))
return(fit1)
})
names(lmm_all) <- formula_vec
var_aic <- aictab(lmm_all, second.ord=TRUE, sort=TRUE) #rank based on AICc
r <- rsquared(lmm_all) #gives R^2 values for models. "Marginal" is the R^2 for just the fixed effects, "Conditional" is the R^2 for everything.
View(var_aic)
##6aii. coefficients ####
best <- lmm_all[[53]]
coef(summary(best))[ , "Estimate"]
##6aii. coefficients ####
best <- lmm_all[[64]]
coef(summary(best))[ , "Estimate"]
